##
## Copyright (c) 2019 Matthias Tafelmeier.
##
## This file is part of godon
##
## godon is free software: you can redistribute it and/or modify
## it under the terms of the GNU Affero General Public License as
## published by the Free Software Foundation, either version 3 of the
## License, or (at your option) any later version.
##
## godon is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU Affero General Public License for more details.
##
## You should have received a copy of the GNU Affero General Public License
## along with this godon. If not, see <http://www.gnu.org/licenses/>.
##
version: '3.4'
services:
    control_loop:
        build:
          context: ./
          dockerfile: ./Dockerfile-airflow
        restart: always
        environment:
            - AIRFLOW__CORE__ENABLE_XCOM_PICKLING=true
            - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=True
            - AIRFLOW__CORE__EXECUTOR=LocalExecutor
            - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@db/airflow
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@db/airflow
            - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
            - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
            - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth
            - 'AIRFLOW_CONN_LINUX_NETWORK_STACK_BREEDER_SSH={ "conn_type": "ssh", "login": "godon_robot", "host": "10.0.5.53", "port": 22, "extra": { "key_file": "/opt/airflow/credentials/id_rsa" } }'
        # minimum of setup steps
        # on sequencial executor and local sqlite
        entrypoint: bash -c "airflow db init; airflow users create -u airflow -p airflow -r Admin -f airflow -l airflow -e airflow; (airflow scheduler &); airflow webserver"
        volumes:
            - ./testing/infra/credentials/ssh/:/opt/airflow/credentials/
            - ./breeder/dags:/opt/airflow/dags/
        ports:
            - 127.0.0.1:8080:8080
    db:
      image: postgres:13
      environment:
        POSTGRES_USER: airflow
        POSTGRES_PASSWORD: airflow
        POSTGRES_DB: airflow
      volumes:
          - postgres-db-volume:/var/lib/postgresql/data
      healthcheck:
        test: ["CMD", "pg_isready", "-U", "airflow"]
        interval: 5s
        retries: 5
      restart: always
    api:
        build:
          context: ./api/flask/
        image: godon/api:latest
        restart: always
        environment:
          - AIRFLOW__URL=http://control_loop:8080
          - ARCHIVE_DB_URL=http://archive_db:5433
        volumes:
            - ./breeder/linux_network_stack/:/usr/src/app/openapi_server/templates/
            - ./breeder/dags:/usr/src/app/openapi_server/dags/
        ports:
          - 127.0.0.1:9100:8080
    nats: # queueing system for decoupling dags
        image: nats:2.9.15
        restart: always
        command: "--name nats_server"
        ports:
          - 127.0.0.1:4222:4222
          - 127.0.0.1:8222:8222
    # for optuna parallel metaheuristics execution on dask
    dask_scheduler:
      build:
          context: ./
          dockerfile: ./Dockerfile-dask
      hostname: dask-scheduler
      ports:
        - "8786:8786"
        - "8787:8787"
      command: ["dask-scheduler"]
    dask_worker:
      build:
        context: ./
        dockerfile: ./Dockerfile-dask
      command: ["dask-worker", "tcp://dask_scheduler:8786"]
      deploy:
        replicas: 2
    prometheus:
      image: prom/prometheus
      volumes:
        - ./testing/:/etc/prometheus/
      ports:
          - 9090:9090
    archive_db:
      image: yugabytedb/yugabyte:2.18.1.0-b84
      container_name: "${DB_CONTAINER_NAME:-yugabytedb}"
      ports:
        - ${DB_YSQL_PORT:-5433}:5433
        - ${DB_YCQL_PORT:-9042}:9042
        # Admin UI
        - ${DB_MASTER_PORT:-7001}:7000
        - ${DB_TSERVER_PORT:-9000}:9000
      command: [
        "bin/yugabyted", "start",
        "--base_dir=/home/yugabyte/yb_data",
        "--daemon=false"
        ]

volumes:
  postgres-db-volume:

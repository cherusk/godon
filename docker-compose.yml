##
## Copyright (c) 2019 Matthias Tafelmeier.
##
## This file is part of godon
##
## godon is free software: you can redistribute it and/or modify
## it under the terms of the GNU Affero General Public License as
## published by the Free Software Foundation, either version 3 of the
## License, or (at your option) any later version.
##
## godon is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU Affero General Public License for more details.
##
## You should have received a copy of the GNU Affero General Public License
## along with this godon. If not, see <http://www.gnu.org/licenses/>.
##
version: '3.4'
services:
    control_loop:
        image: apache/airflow:2.4.3-python3.9
        restart: always
        environment:
            - AIRFLOW__CORE__ENABLE_XCOM_PICKLING=true
            - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=True
            - AIRFLOW__CORE__EXECUTOR=DaskExecutor
            - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@db/airflow
            - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@db/airflow
            - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
            - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
            - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth
            - AIRFLOW__DASK_CLUSTER_ADDRESS=tcp://dask-scheduler-airflow:8786
            - 'AIRFLOW_CONN_LINUX_NETWORK_STACK_BREEDER_SSH={ "conn_type": "ssh", "login": "godon_robot", "host": "10.0.5.53", "port": 22, "extra": { "key_file": "/opt/airflow/credentials/id_rsa" } }'
            - ARCHIVE_DB_USER=yugabyte
            - ARCHIVE_DB_PASSWORD=yugabyte
            - ARCHIVE_DB_HOST=archive-db
            - ARCHIVE_DB_PORT=5433
            - ARCHIVE_DB_DATABASE=archive_db
            - META_DB_USER=meta_data
            - META_DB_PASSWORD=meta_data
            - META_DB_HOSTNAME=meta-data-db
            - META_DB_PORT=5433
            - DLM_DB_USER=
            - DLM_DB_PASSWORD=
            - DLM_DB_HOST=locks_db
            - DLM_DB_DATABASE=distributed_locking
            - DASK_ENDPOINT=dask_scheduler:8786
            - NATS_SERVER_URL="nats://godon_nats_1:4222"
            - PROMETHEUS_URL="http://prometheus:9090"
        # minimum of setup steps
        # on sequencial executor and local sqlite
        entrypoint: bash -c "airflow db init; airflow users create -u airflow -p airflow -r Admin -f airflow -l airflow -e airflow; (airflow scheduler &); airflow webserver"
        volumes:
            - ./testing/infra/credentials/ssh/:/opt/airflow/credentials/
            - ./breeder/dags:/opt/airflow/dags/
        ports:
            - 127.0.0.1:8080:8080
    meta_data_db:
      hostname: meta-data-db
      image: postgres:13
      environment:
        POSTGRES_USER: meta_data
        POSTGRES_PASSWORD: meta_data
        POSTGRES_DB: meta_data
      volumes:
        - postgres-meta-data-db-volume:/var/lib/postgresql/data
      healthcheck:
        test: ["CMD", "pg_isready", "-U", "meta_data"]
        interval: 5s
        retries: 5
      restart: always
    db:
      image: postgres:13
      environment:
        POSTGRES_USER: airflow
        POSTGRES_PASSWORD: airflow
        POSTGRES_DB: airflow
      volumes:
          - postgres-db-volume:/var/lib/postgresql/data
      healthcheck:
        test: ["CMD", "pg_isready", "-U", "airflow", "-d", "airflow"]
        interval: 5s
        retries: 5
      restart: always
    locks_db:
      image: postgres:13
      environment:
        POSTGRES_USER: locking
        POSTGRES_PASSWORD: locking
        POSTGRES_DB: distributed_locking
      volumes:
          - postgres-locking-db-volume:/var/lib/postgresql/data
      healthcheck:
        test: ["CMD", "pg_isready", "-U", "locking", "-d", "distributed_locking"]
        interval: 5s
        retries: 5
      restart: always
    api:
        build:
          context: ./api/flask/
        image: godon/api:latest
        restart: always
        environment:
          - AIRFLOW__URL=http://control_loop:8080
          - ARCHIVE_DB_HOSTNAME=archive-db
          - ARCHIVE_DB_PORT=5433
        volumes:
            - ./breeder/linux_network_stack/:/usr/src/app/openapi_server/templates/
            - ./breeder/dags:/usr/src/app/openapi_server/dags/
        ports:
          - 127.0.0.1:9100:8080
    nats: # queueing system for decoupling dags
        image: nats:2.9.15
        restart: always
        command: "--name nats_server"
        ports:
          - 127.0.0.1:4222:4222
          - 127.0.0.1:8222:8222
    # for airflow engine
    dask_scheduler_airflow:
      build:
          context: ./
          dockerfile: ./Dockerfile-dask
      hostname: dask-scheduler-airflow
      ports:
        - 127.0.0.10:8786:8786
        - 127.0.0.10:8787:8787
      command: ["dask-scheduler"]
    dask_worker_airflow:
      build:
        context: ./
        dockerfile: ./Dockerfile-dask
      command: ["dask-worker", "tcp://dask-scheduler-airflow:8786"]
      deploy:
        replicas: 2
    # for optuna parallel metaheuristics execution on dask
    dask_scheduler:
      build:
          context: ./
          dockerfile: ./Dockerfile-dask
      hostname: dask-scheduler
      ports:
        - 127.0.0.11:8786:8786
        - 127.0.0.11:8787:8787
      command: ["dask-scheduler"]
    dask_worker:
      build:
        context: ./
        dockerfile: ./Dockerfile-dask
      command: ["dask-worker", "tcp://dask_scheduler:8786"]
      deploy:
        replicas: 2
    prometheus:
      image: prom/prometheus
      volumes:
        - ./testing/:/etc/prometheus/
      ports:
          - 9090:9090
    archive_db:
      image: yugabytedb/yugabyte:2.18.1.0-b84
      hostname: archive-db
      environment:
        - "YSQL_DB=archive_db"
      ports:
        - ${DB_YSQL_PORT:-5433}:5433
        - ${DB_YCQL_PORT:-9042}:9042
        # Admin UI
        - ${DB_MASTER_PORT:-7001}:7000
        - ${DB_TSERVER_PORT:-9000}:9000
      command: [
        "bin/yugabyted", "start",
        "--base_dir=/home/yugabyte/yb_data",
        "--daemon=false"
        ]

volumes:
  postgres-db-volume:
  postgres-locking-db-volume:
  postgres-meta-data-db-volume:
